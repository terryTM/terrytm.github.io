<!DOCTYPE html>
<html>

  
<!-- Mirrored from yang-song.github.io/ by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 06 Jun 2022 14:45:30 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title> Terry Ma</title>
<meta name="description" content="Terry Ma's academic website.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://raw.githubusercontent.com/jwarby/jekyll-pygments-themes/master/github.css" >
<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>♾️</text></svg>">

<link rel="stylesheet" href="assets/css/main.css">

<link rel="canonical" href="index.html">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-69768980-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-69768980-1');
  </script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="index.html">
              About
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="experience/index.html">
                Experience
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="publications/index.html">
                Publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="blog/index.html">
              Blog
              
            </a>
          </li>
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Terry Ma </span> 
    </h1>
     <p class="desc">Undergraduate Computer Science Student at <a href="https://www.cc.gatech.edu/">College of Computing, Georgia Tech</a>.</p>
     
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="assets/img/profile.png">
      
      
    </div>
    

    <div class="clearfix" style="text-align: justify; hyphens: none;" lang='en-US'>
      <p>My name is Terry Ma. I am pursuing a BS in Computer Science at the <a href="https://www.gatech.edu/">Georgia Institute of Technology</a>.</p>

<p><strong>Research Interests:</strong> I work on machine learning and artificial intelligence. In particular I work on its applications ranging from public safety and medical diagnosis</p>

<p><strong>Current and Previous Work:</strong> I am currently a research intern at <a href="https://sites.uwm.edu/dabaghlab/">Dabagh Lab</a> funded by the <a href="http://www.computationalscience.org/xsede-empower/">XSEDE EMPOWER</a> research grant. I have previously interned at Jun Liu Lab at Harvard University and Yao Xie Lab at Georgia Tech.</p>

<p><strong>My CV can be downloaded here</strong>. (<a href="assets/pdf/cv.pdf">Curriculum Vitae</a>)</p>

<!--**Contact**:  <span style="font-family:'Lucida Console', monospace">yangsong [at] cs.stanford.edu</span>>-->


    </div>

    
    <div class="social">
      <div class="contact-icons">
        <a href="mailto:terryma@gatech.edu"><i class="fas fa-envelope"></i></a>
<a href="https://twitter.com/terry_t_ma" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
<a href="https://scholar.google.com/citations?user=OBVRcTgAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
<a href="https://github.com/terryTM" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/terry-ma-93b849149" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>












      </div>
      <div class="contact-note">I am on these social platforms. Email is the best way to reach me.
</div>
    </div>
    

    
      <div class="news">
  <h2>News</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Mar 31, 2021</th>
          <td>
            
              Our paper <a href="https://arxiv.org/abs/2011.13456">Score-Based Generative Modeling through Stochastic Differential Equations</a> received an Outstanding Paper Award at ICLR 2021!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jul 1, 2020</th>
          <td>
            
              I received the inaugural <a href="https://machinelearning.apple.com/updates/introducing-apple-scholars-aiml">Apple Ph.D. Fellowship in AI/ML</a>, and the <a href="https://www.jpmorgan.com/insights/technology/artificial-intelligence/awards/phd-fellowship-award-recipients-2020">J.P. Morgan AI Research Ph.D. Fellowship</a>. Thank you Apple! Thank you J.P. Morgan!


            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>Selected Publications <a href="publications/index.html">[full list]</a></h2>
  (*) denotes joint first authorship
  <br>
  <br>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICLR</abbr>
            
    
    
  
  </div>

  <div id="song2022solving" class="col-sm-9">
    
      <div class="title">Solving Inverse Problems in Medical Imaging with Score-Based Generative Models
	</div>
      <div class="author">
        
                  
          
          
          
          
          

          
            
              
                <em>Yang Song</em>*,
              
            
          
        
                  
          
          
          
          
          

          
            
              
                
                  Liyue Shen*,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  <a href="https://med.stanford.edu/xinglab.html" target="_blank">Lei Xing</a>,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  and <a href="https://cs.stanford.edu/~ermon/" target="_blank">Stefano Ermon</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>The 10th International Conference on Learning Representations, 2022. Abridged in the NeurIPS 2021 Workshop on Deep Learning and Inverse Problems.</em>
            
      </div>
    

    

      

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
    
      
      <a href="https://arxiv.org/abs/2111.08005" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/yang-song/score_inverse_problems" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>
	Reconstructing medical images from partial measurements is an important inverse problem in Computed Tomography (CT) and Magnetic Resonance Imaging (MRI). Existing solutions based on machine learning typically train a model to directly map measurements to medical images, leveraging a training dataset of paired images and measurements. These measurements are typically synthesized from images using a fixed physical model of the measurement process, which hinders the generalization capability of models to unknown measurement processes. To address this issue, we propose a fully unsupervised technique for inverse problem solving, leveraging the recently introduced score-based generative models. Specifically, we first train a score-based generative model on medical images to capture their prior distribution. Given measurements and a physical model of the measurement process at test time, we introduce a sampling method to reconstruct an image consistent with both the prior and the observed measurements. Our method does not assume a fixed measurement process during training, and can thus be flexibly adapted to different measurement processes at test time. Empirically, we observe comparable or better performance to supervised learning techniques in several medical imaging tasks in CT and MRI, while demonstrating significantly better generalization to unknown measurement processes.
	</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
            
    
    <span class="award badge">Spotlight</span>
    
    
  
  </div>

  <div id="song2021mle" class="col-sm-9">
    
      <div class="title">Maximum Likelihood Training of Score-Based Diffusion Models</div>
      <div class="author">
        
                  
          
          
          
          
          

          
            
              
                <em>Yang Song</em>*,
              
            
          
        
                  
          
          
          
          
          

          
            
              
                
                  Conor Durkan*,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  <a href="https://homepages.inf.ed.ac.uk/imurray2/" target="_blank">Iain Murray</a>,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  and <a href="https://cs.stanford.edu/~ermon/" target="_blank">Stefano Ermon</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>The 35th Conference on Neural Information Processing Systems, 2021.</em>
            
      </div>
    

    
      <span class="honor">
        <strong>Spotlight Presentation [top 3%]</strong>
      </span>
      

      

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
    
      
      <a href="https://arxiv.org/abs/2101.09258" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/yang-song/score_flow" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      
      <a href="assets/pdf/NeurIPS2021/score_flow.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>
	Score-based diffusion models synthesize samples by reversing a stochastic process that diffuses data to noise, and are trained by minimizing a weighted combination of score matching losses. The log-likelihood of score-based diffusion models can be tractably computed through a connection to continuous normalizing flows, but log-likelihood is not directly optimized by the weighted combination of score matching losses. We show that for a specific weighting scheme, the objective upper bounds the negative log-likelihood, thus enabling approximate maximum likelihood training of score-based diffusion models. We empirically observe that maximum likelihood training consistently improves the likelihood of score-based diffusion models across multiple datasets, stochastic processes, and model architectures. Our best models achieve negative log-likelihoods of 2.83 and 3.76 bits/dim on CIFAR-10 and ImageNet 32x32 without any data augmentation, on a par with state-of-the-art autoregressive models on these tasks.
	</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICML</abbr>
            
    
    
  
  </div>

  <div id="song2021nonlinear" class="col-sm-9">
    
      <div class="title">Accelerating Feedforward Computation via Parallel Nonlinear Equation Solving</div>
      <div class="author">
        
                  
          
          
          
          
          

          
            
              
                <em>Yang Song</em>,
              
            
          
        
                  
          
          
          
          
          

          
            
              
                
                  Chenlin Meng,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  <a href="http://www.cs.toronto.edu/~rjliao/" target="_blank">Renjie Liao</a>,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  and <a href="https://cs.stanford.edu/~ermon/" target="_blank">Stefano Ermon</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>The 38th International Conference on Machine Learning, 2021.</em>
            
      </div>
    

    

      

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
    
      
      <a href="https://arxiv.org/abs/2002.03629" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/ermongroup/fast_feedforward_computation" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      
      <a href="assets/pdf/ICML2021/fast_sampling.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>
	Feedforward computation, such as evaluating a neural network or sampling from an autoregressive model, is ubiquitous in machine learning. The sequential nature of feedforward computation, however, requires a strict order of execution and cannot be easily accelerated with parallel computing. To enable parallelization, we frame the task of feedforward computation as solving a system of nonlinear equations. We then propose to find the solution using a Jacobi or Gauss-Seidel fixed-point iteration method, as well as hybrid methods of both. Crucially, Jacobi updates operate independently on each equation and can be executed in parallel. Our method is guaranteed to give exactly the same values as the original feedforward computation with a reduced (or equal) number of parallel iterations, and hence reduced time given sufficient parallel computing power. Experimentally, we demonstrate the effectiveness of our approach in accelerating (i) backpropagation of RNNs; (ii) evaluation of DenseNets; and (iii) autoregressive sampling of MADE and PixelCNN++, with speedup factors between 1.12 and 33 under various settings.
	</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICLR</abbr>
            
    
    <span class="award badge">Oral</span>
    
    
    <span class="award badge">Award</span>
    
  
  </div>

  <div id="song2021score" class="col-sm-9">
    
      <div class="title">Score-Based Generative Modeling through Stochastic Differential Equations</div>
      <div class="author">
        
                  
          
          
          
          
          

          
            
              
                <em>Yang Song</em>,
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  <a href="https://scholar.google.com/citations?user=-3zYIjQAAAAJ&amp;hl=en" target="_blank">Jascha Sohl-Dickstein</a>,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  <a href="http://dpkingma.com/" target="_blank">Diederik P. Kingma</a>,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  <a href="https://scholar.google.com/citations?user=6vghMS0AAAAJ&amp;hl=en" target="_blank">Abhishek Kumar</a>,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  <a href="https://cs.stanford.edu/~ermon/" target="_blank">Stefano Ermon</a>,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  and <a href="https://scholar.google.com/citations?hl=en&amp;user=i5FMLA4AAAAJ&amp;view_op=list_works" target="_blank">Ben Poole</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>The 9th International Conference on Learning Representations, 2021.</em>
            
      </div>
    

    
      <span class="honor">
        <strong>Outstanding Paper Award</strong>
      </span>
      

      

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
    
      
      <a href="https://arxiv.org/abs/2011.13456" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
      <a href="blog/2021/score/index.html" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
      <a href="https://github.com/yang-song/score_sde" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      
      <a href="assets/pdf/ICLR2021/score_sde.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    
      <a href="https://thegradientpub.substack.com/p/update-2-killer-robots-and-diffusion" class="btn btn-sm z-depth-0" role="button" target="_blank">Media</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>
	Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. 
	Crucially, the reverse-time SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in score-based generative modeling and diffusion probabilistic modeling, allowing for new sampling procedures and new modeling capabilities. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, but additionally enables exact likelihood computation, and improved sampling efficiency. In addition, we provide a new way to solve inverse problems with score-based models, as demonstrated with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 2.99 bits/dim, and demonstrate high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model.
	</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
            
    
    
  
  </div>

  <div id="song2020improved" class="col-sm-9">
    
      <div class="title">Improved Techniques for Training Score-Based Generative Models</div>
      <div class="author">
        
                  
          
          
          
          
          

          
            
              
                <em>Yang Song</em>,
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  and <a href="https://cs.stanford.edu/~ermon/" target="_blank">Stefano Ermon</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>The 34th Conference on Neural Information Processing Systems, 2020.</em>
            
      </div>
    

    

      

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
    
      
      <a href="https://arxiv.org/abs/2006.09011" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
      <a href="blog/2021/score/index.html" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
      <a href="https://github.com/ermongroup/ncsnv2" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      
      <a href="assets/pdf/NeurIPS2020/ncsnv2-poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>
    Score-based generative models can produce high quality image samples comparable to GANs, without requiring adversarial optimization. However, existing training procedures are limited to images of low resolution (typically below 32x32), and can be unstable under some settings. We provide a new theoretical analysis of learning and sampling from score models in high dimensional spaces, explaining existing failure modes and motivating new solutions that generalize across datasets. To enhance stability, we also propose to maintain an exponential moving average of model weights. With these improvements, we can effortlessly scale score-based generative models to images with unprecedented resolutions ranging from 64x64 to 256x256. Our score-based models can generate high-fidelity samples that rival best-in-class GANs on various image datasets, including CelebA, FFHQ, and multiple LSUN categories.
  </p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">AISTATS</abbr>
            
    
    
  
  </div>

  <div id="niu2020permutation" class="col-sm-9">
    
      <div class="title">Permutation Invariant Graph Generation via Score-Based Generative Modeling</div>
      <div class="author">
        
                  
          
          
          
          
          

          
            
              
                
                  Chenhao Niu,
                
              
            
          
        
                  
          
          
          
          
          

          
            
              
                <em>Yang Song</em>,
              
            
          
        
                  
          
          
          
          
          

          
            
              
                
                  Jiaming Song,
                
              
            
          
        
                  
          
          
          
          
          

          
            
              
                
                  Shengjia Zhao,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  <a href="https://aditya-grover.github.io/" target="_blank">Aditya Grover</a>,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  and <a href="https://cs.stanford.edu/~ermon/" target="_blank">Stefano Ermon</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>The 23rd International Conference on Artificial Intelligence and Statistics, 2020.</em>
            
      </div>
    

    

      

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
    
      
      <a href="https://arxiv.org/abs/2003.00638" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/ermongroup/GraphScoreMatching" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>
    Learning generative models for graph structured data is challenging because graphs are discrete, combinatorial, and the underlying data distribution is invariant to the ordering of nodes. However, most of the existing generative models for graphs are not invariant to the chosen ordering, which might lead to an undesirable bias in the learned distribution. To address this difficulty, we propose a permutation invariant approach to modeling graphs, using the recent framework of score-based generative modeling. In particular, we design a permutation equivariant, multi-channel graph neural network to model the gradient of the data distribution at the input graph (a.k.a., the score function). This permutation equivariant model of gradients implicitly defines a permutation invariant distribution for graphs. We train this graph neural network with score matching and sample from it with annealed Langevin dynamics. In our experiments, we first demonstrate the capacity of this new architecture in learning discrete graph algorithms. For graph generation, we find that our learning approach achieves better or comparable results to existing models on benchmark datasets.
  </p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
            
    
    <span class="award badge">Oral</span>
    
    
  
  </div>

  <div id="song2019generative" class="col-sm-9">
    
      <div class="title">Generative Modeling by Estimating Gradients of the Data Distribution</div>
      <div class="author">
        
                  
          
          
          
          
          

          
            
              
                <em>Yang Song</em>,
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  and <a href="https://cs.stanford.edu/~ermon/" target="_blank">Stefano Ermon</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>The 33rd Conference on Neural Information Processing Systems, 2019.</em>
            
      </div>
    

    
      <span class="honor">
        <strong>Oral Presentation [top 0.5%]</strong>
      </span>
      

      

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
    
      
      <a href="https://arxiv.org/abs/1907.05600" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
      <a href="blog/2021/score/index.html" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
      <a href="https://github.com/ermongroup/ncsn" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      
      <a href="assets/pdf/NeurIPS2019/ncsn-poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
      
      <a href="assets/pdf/NeurIPS2019/talk_public.pptx" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    
      <a href="https://www.youtube.com/watch?v=Oc3X_x1Q1jU" class="btn btn-sm z-depth-0" role="button" target="_blank">Media</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>
  We introduce a new generative model where samples are produced via Langevin dynamics using gradients of the data distribution estimated with score matching. Because gradients might be ill-defined when the data resides on low-dimensional manifolds, we perturb the data with different levels of Gaussian noise and jointly estimate the corresponding scores, i.e., the vector fields of gradients of the perturbed data distribution for all noise levels. For sampling, we propose an annealed Langevin dynamics where we use gradients corresponding to gradually decreasing noise levels as the sampling process gets closer to the data manifold. Our framework allows flexible model architectures, requires no sampling during training or the use of adversarial methods, and provides a learning objective that can be used for principled model comparisons. Our models produce samples comparable to GANs on MNIST, CelebA and CIFAR-10 datasets, achieving a new state-of-the-art inception score of 8.87 on CIFAR-10. Additionally, we demonstrate that our models learn effective representations via image inpainting experiments.
  </p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">UAI</abbr>
            
    
    <span class="award badge">Oral</span>
    
    
  
  </div>

  <div id="song2019sliced" class="col-sm-9">
    
      <div class="title">Sliced Score Matching: A Scalable Approach to Density and Score
               Estimation</div>
      <div class="author">
        
                  
          
          
          
          
          

          
            
              
                <em>Yang Song</em>*,
              
            
          
        
                  
          
          
          
          
          

          
            
              
                
                  Sahaj Garg*,
                
              
            
          
        
                  
          
          
          
          
          

          
            
              
                
                  Jiaxin Shi,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  and <a href="https://cs.stanford.edu/~ermon/" target="_blank">Stefano Ermon</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>The 35th Conference on Uncertainty in Artificial Intelligence, 2019.</em>
            
      </div>
    

    
      <span class="honor">
        <strong>Oral Presentation [top 8.7%]</strong>
      </span>
      

      

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
    
      
      <a href="https://arxiv.org/abs/1905.07088" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
      <a href="https://ermongroup.github.io/blog/ssm/" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
      <a href="https://github.com/ermongroup/sliced_score_matching" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>
    Score matching is a popular method for estimating unnormalized statistical models. However, it has been so far limited to simple models or low-dimensional data, due to the difficulty of computing the trace of Hessians for log-density functions. We show this difficulty can be mitigated by sliced score matching, a new objective that matches random projections of the original scores. Our objective only involves Hessian-vector products, which can be easily implemented using reverse-mode auto-differentiation. This enables scalable score matching for complex models and higher dimensional data. Theoretically, we prove the consistency and asymptotic normality of sliced score matching. Moreover, we demonstrate that sliced score matching can be used to learn deep score estimators for implicit distributions. In our experiments, we show that sliced score matching greatly outperforms competitors on learning deep energy-based models, and can produce accurate score estimates for applications such as variational inference with implicit distributions and training Wasserstein Auto-Encoders.
  </p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
            
    
    
  
  </div>

  <div id="song2018construct" class="col-sm-9">
    
      <div class="title">
    Constructing Unrestricted Adversarial Examples with Generative Models
  </div>
      <div class="author">
        
                  
          
          
          
          
          

          
            
              
                <em>Yang Song</em>,
              
            
          
        
                  
          
          
          
          
          

          
            
              
                
                  Rui Shu,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  <a href="http://www.kushman.org/" target="_blank">Nate Kushman</a>,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  and <a href="https://cs.stanford.edu/~ermon/" target="_blank">Stefano Ermon</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>The 32nd Conference on Neural Information Processing Systems, 2018.</em>
            
      </div>
    

    

      

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
    
      
      <a href="https://arxiv.org/abs/1805.07894" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/ermongroup/generative_adversary" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      
      <a href="assets/pdf/NeurIPS2018/uae-poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    
      <a href="https://twitter.com/goodfellow_ian/status/999035763596578816" class="btn btn-sm z-depth-0" role="button" target="_blank">Media</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>
    Adversarial examples are typically constructed by perturbing an existing data point within a small matrix norm, and current defense methods are focused on guarding against this type of attack. In this paper, we propose unrestricted adversarial examples, a new threat model where the attackers are not restricted to small norm-bounded perturbations. Different from perturbation-based attacks, we propose to synthesize unrestricted adversarial examples entirely from scratch using conditional generative models. Specifically, we first train an Auxiliary Classifier Generative Adversarial Network (AC-GAN) to model the class-conditional distribution over data samples. Then, conditioned on a desired class, we search over the AC-GAN latent space to find images that are likely under the generative model and are misclassified by a target classifier. We demonstrate through human evaluation that unrestricted adversarial examples generated this way are legitimate and belong to the desired class. Our empirical results on the MNIST, SVHN, and CelebA datasets show that unrestricted adversarial examples can bypass strong adversarial training and certified defense methods designed for traditional adversarial attacks.
  </p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICLR</abbr>
            
    
    
  
  </div>

  <div id="song2018pixeldefend" class="col-sm-9">
    
      <div class="title">
    PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples
  </div>
      <div class="author">
        
                  
          
          
          
          
          

          
            
              
                <em>Yang Song</em>,
              
            
          
        
                  
          
          
          
          
          

          
            
              
                
                  Taesup Kim,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  <a href="http://www.nowozin.net/sebastian/" target="_blank">Sebastian Nowozin</a>,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  <a href="https://cs.stanford.edu/~ermon/" target="_blank">Stefano Ermon</a>,
                
              
            
          
        
                  
          
          
          
          
          
            
              
                
                
          

          
            
              
                
                  and <a href="http://www.kushman.org/" target="_blank">Nate Kushman</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>
    The 6th International Conference on Learning Representations, 2018.
  </em>
            
      </div>
    

    

      

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
    
      
      <a href="https://arxiv.org/abs/1710.10766" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/Microsoft/PixelDefend/" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      
      <a href="assets/pdf/ICLR2018/pixeldefend-poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>
    Adversarial perturbations of normal images are usually imperceptible to humans, but they can seriously confuse state-of-the-art machine learning models. What makes them so special in the eyes of image classifiers? In this paper, we show empirically that adversarial examples mainly lie in the low probability regions of the training distribution, regardless of attack types and targeted models. Using statistical hypothesis testing, we find that modern neural density models are surprisingly good at detecting imperceptible image perturbations. Based on this discovery, we devised PixelDefend, a new approach that purifies a maliciously perturbed image by moving it back towards the distribution seen in the training data. The purified image is then run through an unmodified classifier, making our method agnostic to both the classifier and the attacking method. As a result, PixelDefend can be used to protect already deployed models and be combined with other model-specific defenses. Experiments show that our method greatly improves resilience across a wide variety of state-of-the-art attacking methods, increasing accuracy on the strongest attack from 63% to 84% for Fashion MNIST and from 32% to 70% for CIFAR-10.
  </p>
    </div>
    
  </div>
</div>
</li></ol>
</div>

    

    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2022 Terry Ma.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="assets/js/common.js"></script>



<!-- Mirrored from yang-song.github.io/ by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 06 Jun 2022 14:47:41 GMT -->
</html>
